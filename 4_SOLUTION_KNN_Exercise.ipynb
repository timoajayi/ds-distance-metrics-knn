{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Exercise\n",
    "\n",
    "![iris](images/iris.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the famous **iris data set** again. \n",
    "\n",
    "The dataset consists of four attributes, which can be used to distinguish different iris species: \n",
    "* sepal-width\n",
    "* sepal-length\n",
    "* petal-width \n",
    "* petal-length. \n",
    "\n",
    "\n",
    "The task is to predict the class to which these plants belong. There are three classes in the dataset: **Iris-setosa, Iris-versicolor and Iris-virginica.** \n",
    "\n",
    "Further details of the dataset are available here.\n",
    "https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Please import and preprocess the data (as far as it's necessary). Afterwards split it in a train and test set, fit a KNN model and make predictions on the test set. The last step is to evaluate your model. Try to also scale your data and fit the model to the unscaled and scaled data. Can you see a difference in performance?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Please also calculate the accuracy for K values of 1 to 40. In each iteration the accuracy for the predicted values of the test set is calculated and the result is appended to an error list.\n",
    "The next step is to plot the accuracy values against K values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Task 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import some libraries, as we will need them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations \n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having unziped the data, and located at successfully in data/iris.csv, we can read it into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/iris.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's quickly check if the import worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On first glance, everything looks fine. Let's check the datatypes and see if we have missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also looks fine: \n",
    "- No missing values\n",
    "- all features are floats (numerical) \n",
    "- only the target is an object (=string)\n",
    "\n",
    "Next, let's quickly have a look at the distribution of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=df.describe().T\n",
    "display(desc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. as well as the spanned range for each feature and the zscores for the edge-observations (to check for outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc['range']=desc['max'] - desc['min']\n",
    "desc['zscore_min']=(desc['mean']-desc['min']) / desc['std']\n",
    "desc['zscore_max']=(desc['max']-desc['mean']) / desc['std']\n",
    "display(desc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shouldn't run into big issues here, but we could check later if scaling improves things - after all the range of the feature ```petal_length``` is more then twice as large as from the ```xxx_width``` features.\n",
    "\n",
    "A z-score threshold of 3 is often used for outlier detection. There is at least one observation that could be considered to be an outlier with regards to the ```sepal_width```. Let's identify these 'outliers':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find outliers according to zscore > 3 criterion\n",
    "features=df.columns.drop('species')\n",
    "zscores=zscore(df[features])\n",
    "is_outlier=(zscores>3).values\n",
    "\n",
    "print('These are the outliers:')\n",
    "outliers=df[features][is_outlier]\n",
    "display(outliers)\n",
    "\n",
    "print('These are their zscores:')\n",
    "display(zscores[is_outlier])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it is only one observation that is only slightly above the threshold. We should be able to keep it.\n",
    "\n",
    "It seems that this data set is reasonable clean without any preprocessing required.\n",
    "\n",
    "Next, lets generate some plots to get to a visualisation, inside we can mark the point that was identified as an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,3,figsize=(16,9))\n",
    "ft_combinations=combinations(features,2)\n",
    "for i,(f1,f2) in enumerate(ft_combinations):\n",
    "    sns.scatterplot(data=df,x=f1,y=f2,hue='species',ax=ax[i%2,i%3])\n",
    "    sns.scatterplot(data=outliers,x=f1,y=f2,color='red',s=500,marker='x',ax=ax[i%2,i%3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good! Next, let's check the distributions of the features and see how they are correlated. For that we can use a pairplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df,kind='reg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```petal_length``` and ```petal_width``` show 2 distinct peaks in their histograms. This indicates overlapping distributions. However, we could already identify from the previous plots, that we would be able to seperate one of the species (```iris_setosa```) just based on one of those features. \n",
    "\n",
    "Additionally, we can see, that we have several correlations between the features. Let's check closer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that only includes the numerical variables\n",
    "df_numeric = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "## Upper triangle of an array. \n",
    "## Return a copy of an array with the elements below the k-th diagonal zeroed\n",
    "mask = np.triu(np.ones_like(df_numeric.corr(), dtype=bool))\n",
    "\n",
    "heatmap = sns.heatmap(df_numeric.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap=sns.diverging_palette(20, 220, n=100))\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=16);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the EDA done, we can start building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define the target\n",
    "y=df.species\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale of all features is quite similar. To demonstrate the effect of scaling we artificially inflate the scale of sepal_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sepal_length = df.sepal_length * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the features\n",
    "X=df[features]\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step of the modelling process is, to do a train-test split. In this case we use an unusual small training fraction, because the dataset is already easily seperable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,shuffle=True,stratify=y, train_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Train a KNN Classifier with a starting parameter of 5 neighbors using the euclidean distance as a metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=KNeighborsClassifier(n_neighbors=5,metric='euclidean')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print('\\n\\nConfusion matrix')\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try scaling and normalisation to check if this has an effect on the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std=StandardScaler()\n",
    "norm=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm=norm.fit_transform(X_train)\n",
    "X_test_norm=norm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=KNeighborsClassifier(n_neighbors=5,metric='euclidean')\n",
    "clf.fit(X_train_norm,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test_norm)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print('\\n\\nConfusion matrix')\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std=std.fit_transform(X_train)\n",
    "X_test_std=std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=KNeighborsClassifier(n_neighbors=5,metric='euclidean')\n",
    "clf.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test_std)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print('\\n\\nConfusion matrix')\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is very sensitive to the scale of data as it relies on computing the distances. For features with a higher scale, the calculated distances can be very high and might produce poor results. It is thus advised to scale the data before running the KNN. This is true for all algorithms that rely on computation of distance. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's wrap this into a function that allows us to compute the accuracy for different parameters - i.e. different numbers of neighbors and different orders of the minkovski metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(k=3,metric_p=2):\n",
    "    clf=KNeighborsClassifier(n_neighbors=k,p=metric_p)\n",
    "    clf.fit(X_train,y_train)\n",
    "    res=clf.score(X_test,y_test)\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, we can compute the resulting accuracy for different combinations of the neighbors and distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_neighbors=range(1,40)\n",
    "data=pd.DataFrame(index=n_neighbors)\n",
    "\n",
    "for p in range(1,4):\n",
    "    data[f'p={p}']=[fit_predict(k,p) for k in n_neighbors]\n",
    "data=data.reset_index()  \n",
    "data=data.rename(columns={'index':'NrNeighbors'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_long=pd.wide_to_long(data, ['p='], i='NrNeighbors', j='MinkovskiOrder', sep='').reset_index()\n",
    "data_long=data_long.rename(columns={'p=':'Accuracy'})\n",
    "data_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "highest_accuarcy=np.argsort(data_long.Accuracy)[-3:]\n",
    "best_k=list(data_long.NrNeighbors[highest_accuarcy])\n",
    "sns.lineplot(data=data_long,x='NrNeighbors',y='Accuracy',hue='MinkovskiOrder')\n",
    "ax.vlines(best_k,data_long.Accuracy.min(),data_long.Accuracy.max(),colors='grey',linestyle='dashed')\n",
    "\n",
    "print(f'The best numbers of neighbors in this case is {best_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
